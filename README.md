# üöÄ Data Warehouse + Feature Store para Churn Prediction

## üìå Descripci√≥n

Este proyecto construye un **data warehouse anal√≠tico completo** utilizando dbt, con el objetivo de generar una tabla final de **features para predecir churn** en una empresa SaaS ficticia.

El enfoque replica el trabajo real de un **ML Engineer** y un **Data Engineer**, donde dbt se usa para construir un **pipeline de features diarias** que alimentan un modelo ML.

## üèóÔ∏è Arquitectura

Este proyecto sigue la **arquitectura Medallion** (Bronze-Silver-Gold) con una capa intermedia:

```
raw (Bronze) ‚Üí staging (Silver) ‚Üí intermediate ‚Üí marts (Gold)
```

- **Bronze (raw)**: Datos fuente originales sin procesar
- **Silver (staging)**: Datos limpios y estandarizados
- **Intermediate**: Transformaciones intermedias y agregaciones
- **Gold (marts)**: Datos finales listos para consumo/ML

## üéØ Objetivos

- ‚úÖ Construir un pipeline completo usando dbt (raw ‚Üí staging ‚Üí intermediate ‚Üí marts)
- ‚úÖ Implementar materializaciones (`view`, `table`, `incremental`)
- ‚úÖ Crear modelos agregados y enriquecidos
- ‚úÖ Implementar un **snapshot SCD Type 2** para la tabla de usuarios
- ‚úÖ Generar una tabla **ML-ready** con m√°s de 30 features por usuario
- ‚úÖ Incluir tests automatizados y documentaci√≥n completa
- ‚úÖ CI/CD con GitHub Actions

## üìÅ Estructura del Proyecto

```
proyecto_1_churn_prediction/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îú‚îÄ‚îÄ workflows/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ci.yml          # CI/CD pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lint.yml        # Linting y validaci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ docs.yml        # Generaci√≥n de documentaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ README.md           # Documentaci√≥n de workflows
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ staging/            # Modelos staging (Silver)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_users.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_app_events.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_billing.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_support_tickets.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_marketing.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schema.yml      # Tests y documentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ intermediate/       # Modelos intermedios
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ int_user_events_aggregated.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ int_user_billing_summary.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ int_user_support_metrics.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ int_user_engagement.sql
‚îÇ   ‚îî‚îÄ‚îÄ marts/              # Modelos finales (Gold)
‚îÇ       ‚îú‚îÄ‚îÄ fct_churn_features.sql
‚îÇ       ‚îî‚îÄ‚îÄ schema.yml
‚îú‚îÄ‚îÄ snapshots/              # Snapshots SCD Type 2
‚îÇ   ‚îú‚îÄ‚îÄ snap_users.sql
‚îÇ   ‚îî‚îÄ‚îÄ snap_users_scd2.sql
‚îú‚îÄ‚îÄ notebooks/              # Notebooks ML opcionales
‚îÇ   ‚îî‚îÄ‚îÄ churn_prediction_model.ipynb
‚îú‚îÄ‚îÄ dbt_project.yml         # Configuraci√≥n del proyecto
‚îú‚îÄ‚îÄ profiles.yml            # Configuraci√≥n de conexi√≥n
‚îú‚îÄ‚îÄ requirements.txt        # Dependencias Python
‚îú‚îÄ‚îÄ generate_data.py        # Script para generar datos
‚îî‚îÄ‚îÄ README.md               # Este archivo
```

## üöÄ Quick Start

### Prerrequisitos

- Python 3.8+
- dbt-core >= 1.7.0
- dbt-duckdb >= 1.7.0
- DuckDB >= 0.9.0

### Instalaci√≥n

1. **Clonar el repositorio:**
```bash
git clone https://github.com/DobleL2/dbt_churn_prediction.git
cd dbt_churn_prediction
```

2. **Instalar dependencias:**
```bash
pip install -r requirements.txt
pip install dbt-core dbt-duckdb
```

3. **Generar datos de prueba:**
```bash
python generate_data.py
```

Esto crear√° una base de datos DuckDB (`churn_prediction.duckdb`) con:
- 10,000 usuarios
- ~5M eventos de aplicaci√≥n
- ~33K registros de facturaci√≥n
- ~7.5K tickets de soporte
- ~10K campa√±as de marketing

4. **Ejecutar el pipeline dbt:**
```bash
# Instalar dependencias de dbt
dbt deps --profiles-dir .

# Compilar modelos
dbt compile --profiles-dir .

# Ejecutar modelos
dbt run --profiles-dir .

# Ejecutar tests
dbt test --profiles-dir .

# Ejecutar snapshots
dbt snapshot --profiles-dir .

# Generar documentaci√≥n
dbt docs generate --profiles-dir .
dbt docs serve --profiles-dir .
```

## üìä Modelos Principales

### Staging (Silver Layer)

| Modelo | Descripci√≥n | Filas (ejemplo) |
|--------|-------------|-----------------|
| `stg_users` | Limpieza y estandarizaci√≥n de usuarios | 10,000 |
| `stg_app_events` | Eventos de aplicaci√≥n normalizados | ~5M |
| `stg_billing` | Historial de pagos limpio | ~33K |
| `stg_support_tickets` | Tickets de soporte estandarizados | ~7.5K |
| `stg_marketing` | Campa√±as de marketing limpias | ~10K |

### Intermediate

| Modelo | Descripci√≥n |
|--------|-------------|
| `int_user_events_aggregated` | Agregaciones de eventos por usuario (total, d√≠as activos, tipos, etc.) |
| `int_user_billing_summary` | Resumen de facturaci√≥n (pagos exitosos, monto total, tasa de √©xito) |
| `int_user_support_metrics` | M√©tricas de soporte (tickets por tipo, tasa de resoluci√≥n) |
| `int_user_engagement` | Vista consolidada de engagement del usuario |

### Marts (Gold Layer)

| Modelo | Descripci√≥n | Features |
|--------|-------------|----------|
| `fct_churn_features` | Tabla final ML-ready con features para churn prediction | **30+ features** |

**Features incluidas:**
- Time-based: d√≠as desde signup, meses, trimestre, d√≠a de semana
- Event-based: total eventos, d√≠as activos, tipos de eventos, ratios
- Billing: pagos totales, √©xito, monto, frecuencia
- Support: tickets totales, por tipo, tasa de resoluci√≥n
- Marketing: campa√±as recibidas, engagement rate
- Derived: activity rate, login ratio, click ratio
- Flags: plan type, pa√≠s, indicadores de riesgo

### Snapshots

| Snapshot | Descripci√≥n |
|----------|-------------|
| `snap_users` | Snapshot temporal de usuarios |
| `snap_users_scd2` | Snapshot SCD Type 2 con historial de cambios |

## üß™ Tests

El proyecto incluye tests automatizados para garantizar calidad de datos:

```bash
# Ejecutar todos los tests
dbt test --profiles-dir .

# Ejecutar tests de un modelo espec√≠fico
dbt test --select stg_users --profiles-dir .

# Ejecutar tests de una fuente
dbt test --select source:raw --profiles-dir .
```

**Tipos de tests incluidos:**
- `unique`: Verifica unicidad de claves
- `not_null`: Verifica que campos requeridos no sean nulos
- `relationships`: Verifica integridad referencial
- `accepted_values`: Valida valores permitidos

## üìö Documentaci√≥n

### Generar documentaci√≥n localmente:
```bash
# Importante: Usar --profiles-dir . para usar el profiles.yml local
dbt docs generate --profiles-dir .
dbt docs serve --profiles-dir .
# Abre http://localhost:8080
```

**Nota:** Si ves el error "Could not find adapter type duckdb!", aseg√∫rate de:
1. Tener el entorno virtual activado
2. Tener `dbt-duckdb` instalado: `pip install dbt-duckdb`
3. Usar `--profiles-dir .` en los comandos

Ver m√°s detalles en [`dbt_docs_instructions.md`](dbt_docs_instructions.md)

### Ver documentaci√≥n en GitHub Actions:
1. Ve a la pesta√±a "Actions"
2. Ejecuta el workflow "Generate Docs"
3. Descarga el artefacto "dbt-docs"

## ü§ñ Machine Learning

### Notebook ML Opcional

El proyecto incluye un notebook Jupyter para entrenar un modelo de churn:

```bash
# Instalar dependencias adicionales
pip install scikit-learn matplotlib seaborn jupyter

# Ejecutar notebook
jupyter notebook notebooks/churn_prediction_model.ipynb
```

El notebook:
- Carga features desde `fct_churn_features`
- Entrena un RandomForestClassifier
- Eval√∫a m√©tricas (ROC-AUC, classification report)
- Visualiza importancia de features
- Genera confusion matrix

## üîÑ CI/CD con GitHub Actions

El proyecto incluye workflows automatizados:

### Workflows Disponibles

1. **CI Pipeline** (`.github/workflows/ci.yml`)
   - Se ejecuta en push/PR
   - Genera datos, ejecuta dbt, tests, snapshots
   - Valida calidad de datos

2. **Lint** (`.github/workflows/lint.yml`)
   - Valida sintaxis SQL
   - Verifica parseo de modelos dbt

3. **Docs** (`.github/workflows/docs.yml`)
   - Genera documentaci√≥n autom√°ticamente
   - Se ejecuta diariamente y manualmente

Ver m√°s detalles en [`.github/README.md`](.github/README.md)

## üìà Ejemplos de Uso

### Consultar features para un usuario:
```sql
SELECT 
    user_id,
    total_events,
    active_days,
    total_amount_paid,
    is_churned,
    activity_rate
FROM marts.fct_churn_features
WHERE user_id = 123;
```

### Analizar distribuci√≥n de churn:
```sql
SELECT 
    plan_type,
    COUNT(*) as total_users,
    SUM(CASE WHEN is_churned THEN 1 ELSE 0 END) as churned_users,
    AVG(CASE WHEN is_churned THEN 1.0 ELSE 0.0 END) as churn_rate
FROM marts.fct_churn_features
GROUP BY plan_type;
```

### Ver historial de cambios (snapshot):
```sql
SELECT 
    user_id,
    dbt_valid_from,
    dbt_valid_to,
    status,
    plan_type
FROM snapshots.snap_users_scd2
WHERE user_id = 123
ORDER BY dbt_valid_from;
```

## üêõ Troubleshooting

### Error: "ModuleNotFoundError: No module named 'duckdb'"
```bash
pip install duckdb
```

### Error: "dbt: command not found"
```bash
pip install dbt-core dbt-duckdb
```

### Error: "Database file not found"
```bash
# Regenerar datos
python generate_data.py
```

### Error en tests
```bash
# Ver detalles del error
dbt test --select <modelo> --verbose

# Ejecutar solo tests de staging
dbt test --select staging
```

## üìä M√©tricas del Proyecto

- **Modelos totales**: 14
- **Tests**: 20+
- **Features ML**: 30+
- **Snapshots**: 2
- **L√≠neas de c√≥digo SQL**: ~1,500+

## ü§ù Contribuir

1. Fork el proyecto
2. Crea una rama (`git checkout -b feature/nueva-feature`)
3. Commit tus cambios (`git commit -m 'Agregar nueva feature'`)
4. Push a la rama (`git push origin feature/nueva-feature`)
5. Abre un Pull Request

## üìù Licencia

Este proyecto es para fines educativos y de demostraci√≥n.

## üë§ Autor

**Luis**

---

## üìö Recursos Adicionales

- [Documentaci√≥n de dbt](https://docs.getdbt.com/)
- [DuckDB Documentation](https://duckdb.org/docs/)
- [Arquitectura Medallion](https://www.databricks.com/glossary/medallion-architecture)
